# models - ç¥ç»ç½‘ç»œæ¨¡å‹æ¨¡å—

[æ ¹ç›®å½•](../../CLAUDE.md) > **models**

**æœ€åæ›´æ–°æ—¶é—´**: 2025-11-12T17:29:27+08:00

---

## ğŸ“‹ å˜æ›´æ—¥å¿—

### 2025-11-12
- åˆ›å»ºæ¨¡å—è®¾è®¡æ–‡æ¡£
- å®šä¹‰ U-Net æ¨¡å‹æ¥å£è§„èŒƒ

---

## ğŸ¯ æ¨¡å—èŒè´£

**models** æ¨¡å—è´Ÿè´£æä¾›ç”¨äºæ‰©æ•£æ¨¡å‹çš„ç¥ç»ç½‘ç»œæ¶æ„ï¼Œä¸»è¦ç”¨äºå™ªå£°é¢„æµ‹ä»»åŠ¡ã€‚

### æ ¸å¿ƒåŠŸèƒ½
- å®ç° U-Net æ¶æ„ï¼Œä½œä¸ºæ ‡å‡†çš„å™ªå£°é¢„æµ‹æ¨¡å‹
- æ¥æ”¶å¸¦å™ªæ•°æ®ã€æ—¶é—´æ­¥å’Œæ¡ä»¶ä¿¡æ¯
- è¾“å‡ºé¢„æµ‹çš„å™ªå£°å¼ é‡

---

## ğŸš€ å…¥å£ä¸å¯åŠ¨

### æ¨¡å—çŠ¶æ€
ğŸš§ **è®¡åˆ’ä¸­** - å°šæœªå®ç°

### è®¡åˆ’çš„æ–‡ä»¶ç»“æ„
```
models/
â”œâ”€â”€ __init__.py          # æ¨¡å—åˆå§‹åŒ–ï¼Œå¯¼å‡ºæ¨¡å‹ç±»
â””â”€â”€ unet.py             # U-Net å™ªå£°é¢„æµ‹æ¨¡å‹
```

### ä½¿ç”¨ç¤ºä¾‹ï¼ˆè®¡åˆ’ï¼‰
```python
from models import UNet
import torch

# åˆå§‹åŒ–æ¨¡å‹
model = UNet(
    in_channels=1,      # è¾“å…¥é€šé“æ•°ï¼ˆå¦‚ç°åº¦å›¾ä¸º 1ï¼ŒRGB ä¸º 3ï¼‰
    out_channels=1,     # è¾“å‡ºé€šé“æ•°ï¼ˆé€šå¸¸ä¸è¾“å…¥ç›¸åŒï¼‰
    base_channels=64,   # åŸºç¡€é€šé“æ•°
    channel_multipliers=[1, 2, 4, 8],  # å„å±‚é€šé“å€æ•°
    num_res_blocks=2,   # æ¯å±‚çš„æ®‹å·®å—æ•°é‡
    attention_resolutions=[16, 8]  # ä½¿ç”¨æ³¨æ„åŠ›æœºåˆ¶çš„åˆ†è¾¨ç‡
)

# å‰å‘ä¼ æ’­
batch_size = 4
height, width = 64, 64
x_t = torch.randn(batch_size, 1, height, width)  # å¸¦å™ªæ•°æ®
t = torch.randint(0, 1000, (batch_size,))        # æ—¶é—´æ­¥
condition = torch.randn(batch_size, 1, height, width)  # æ¡ä»¶ï¼ˆå¯é€‰ï¼‰

predicted_noise = model(x_t, t, condition)
print(f"é¢„æµ‹å™ªå£°å½¢çŠ¶: {predicted_noise.shape}")  # åº”ä¸ x_t å½¢çŠ¶ç›¸åŒ
```

---

## ğŸ”Œ å¤–éƒ¨æ¥å£

### UNet ç±»æ¥å£è§„èŒƒ

```python
class UNet(nn.Module):
    """
    U-Net å™ªå£°é¢„æµ‹æ¨¡å‹ã€‚

    Args:
        in_channels (int): è¾“å…¥å›¾åƒé€šé“æ•°
        out_channels (int): è¾“å‡ºå›¾åƒé€šé“æ•°ï¼ˆé€šå¸¸ç­‰äº in_channelsï¼‰
        base_channels (int): åŸºç¡€é€šé“æ•°ï¼Œé»˜è®¤ 64
        channel_multipliers (List[int]): å„å±‚é€šé“æ•°å€å¢å› å­
        num_res_blocks (int): æ¯ä¸ªåˆ†è¾¨ç‡å±‚çš„æ®‹å·®å—æ•°é‡
        attention_resolutions (List[int]): åº”ç”¨æ³¨æ„åŠ›æœºåˆ¶çš„åˆ†è¾¨ç‡åˆ—è¡¨
        dropout (float): Dropout æ¦‚ç‡ï¼Œé»˜è®¤ 0.0
    """

    def forward(self,
                x_t: torch.Tensor,
                t: torch.Tensor,
                condition: torch.Tensor) -> torch.Tensor:
        """
        é¢„æµ‹å™ªå£°ã€‚

        Args:
            x_t (torch.Tensor): å¸¦å™ªæ•°æ®ï¼Œå½¢çŠ¶ [batch_size, in_channels, height, width]
            t (torch.Tensor): æ—¶é—´æ­¥ï¼Œå½¢çŠ¶ [batch_size]
            condition (torch.Tensor): æ¡ä»¶å¼ é‡ï¼Œå½¢çŠ¶ä¸ x_t å…¼å®¹æˆ–å¯å¹¿æ’­

        Returns:
            torch.Tensor: é¢„æµ‹çš„å™ªå£°ï¼Œå½¢çŠ¶ä¸ x_t ç›¸åŒ
        """
```

### å…³é”®ç»„ä»¶

#### 1. æ—¶é—´æ­¥åµŒå…¥ (Time Embedding)
```python
def time_embedding(self, t: torch.Tensor, dim: int) -> torch.Tensor:
    """
    å°†æ—¶é—´æ­¥ t è½¬æ¢ä¸ºé«˜ç»´åµŒå…¥å‘é‡ã€‚

    é€šå¸¸ä½¿ç”¨æ­£å¼¦ä½ç½®ç¼–ç ï¼ˆSinusoidal Positional Encodingï¼‰ï¼š
    - ä½é¢‘åˆ†é‡ï¼šæ•æ‰å…¨å±€æ—¶é—´ä¿¡æ¯
    - é«˜é¢‘åˆ†é‡ï¼šæ•æ‰å±€éƒ¨æ—¶é—´å˜åŒ–

    Args:
        t: æ—¶é—´æ­¥ï¼Œå½¢çŠ¶ [batch_size]
        dim: åµŒå…¥ç»´åº¦

    Returns:
        æ—¶é—´åµŒå…¥ï¼Œå½¢çŠ¶ [batch_size, dim]
    """
```

#### 2. ä¸‹é‡‡æ ·è·¯å¾„ (Downsampling Path)
- é€æ­¥é™ä½ç©ºé—´åˆ†è¾¨ç‡
- å¢åŠ é€šé“æ•°
- æå–å¤šå°ºåº¦ç‰¹å¾

#### 3. ç“¶é¢ˆå±‚ (Bottleneck)
- æœ€ä½åˆ†è¾¨ç‡çš„ç‰¹å¾å¤„ç†
- é€šå¸¸åŒ…å«è‡ªæ³¨æ„åŠ›æœºåˆ¶

#### 4. ä¸Šé‡‡æ ·è·¯å¾„ (Upsampling Path)
- é€æ­¥æ¢å¤ç©ºé—´åˆ†è¾¨ç‡
- é€šè¿‡è·³è·ƒè¿æ¥ (skip connections) èåˆä¸‹é‡‡æ ·ç‰¹å¾

#### 5. æ®‹å·®å— (Residual Block)
```python
class ResidualBlock(nn.Module):
    """
    æ®‹å·®å—ï¼ŒåŒ…å«ï¼š
    - åˆ†ç»„å½’ä¸€åŒ– (Group Normalization)
    - æ¿€æ´»å‡½æ•° (SiLU/Swish)
    - å·ç§¯å±‚
    - æ—¶é—´åµŒå…¥æ³¨å…¥
    - æ®‹å·®è¿æ¥
    """
```

#### 6. è‡ªæ³¨æ„åŠ›æ¨¡å— (Self-Attention)
```python
class AttentionBlock(nn.Module):
    """
    å¤šå¤´è‡ªæ³¨æ„åŠ›æ¨¡å—ï¼Œç”¨äºæ•æ‰é•¿è·ç¦»ä¾èµ–ã€‚
    é€šå¸¸åº”ç”¨äºè¾ƒä½åˆ†è¾¨ç‡çš„ç‰¹å¾å›¾ã€‚
    """
```

---

## ğŸ“¦ å…³é”®ä¾èµ–ä¸é…ç½®

### ä¾èµ–é¡¹
- **PyTorch**: æ·±åº¦å­¦ä¹ æ¡†æ¶
- **torch.nn**: ç¥ç»ç½‘ç»œæ¨¡å—

### é…ç½®å‚æ•°ï¼ˆæ¥è‡ª config.yamlï¼‰

```yaml
model:
  in_channels: 1              # è¾“å…¥é€šé“æ•°
  out_channels: 1             # è¾“å‡ºé€šé“æ•°
  base_channels: 64           # åŸºç¡€é€šé“æ•°
  channel_multipliers: [1, 2, 4, 8]  # é€šé“å€å¢å› å­
  num_res_blocks: 2           # æ®‹å·®å—æ•°é‡
  attention_resolutions: [16, 8]  # æ³¨æ„åŠ›å±‚çš„åˆ†è¾¨ç‡
  dropout: 0.0                # Dropout æ¦‚ç‡
```

### æ¨¡å‹æ¶æ„ç¤ºä¾‹

ä»¥ `base_channels=64`, `channel_multipliers=[1, 2, 4, 8]` ä¸ºä¾‹ï¼š

```
è¾“å…¥: [B, 1, 64, 64]

ä¸‹é‡‡æ ·è·¯å¾„:
  Level 0: [B, 64, 64, 64]   (64x1)
  Level 1: [B, 128, 32, 32]  (64x2) + Attention
  Level 2: [B, 256, 16, 16]  (64x4) + Attention
  Level 3: [B, 512, 8, 8]    (64x8)

ç“¶é¢ˆ:
  [B, 512, 8, 8] + Attention

ä¸Šé‡‡æ ·è·¯å¾„:
  Level 3: [B, 512, 8, 8]    + è·³è·ƒè¿æ¥
  Level 2: [B, 256, 16, 16]  + è·³è·ƒè¿æ¥ + Attention
  Level 1: [B, 128, 32, 32]  + è·³è·ƒè¿æ¥ + Attention
  Level 0: [B, 64, 64, 64]   + è·³è·ƒè¿æ¥

è¾“å‡º: [B, 1, 64, 64]
```

---

## ğŸ“Š æ•°æ®æ¨¡å‹

### è¾“å…¥è¾“å‡ºè§„èŒƒ

| å‚æ•° | å½¢çŠ¶ | ç±»å‹ | è¯´æ˜ |
|------|------|------|------|
| `x_t` | `[B, C, H, W]` | torch.Tensor | å¸¦å™ªæ•°æ® |
| `t` | `[B]` | torch.Tensor (long) | æ—¶é—´æ­¥ç´¢å¼• |
| `condition` | `[B, C, H, W]` | torch.Tensor | æ¡ä»¶ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰ |
| **è¿”å›å€¼** | `[B, C, H, W]` | torch.Tensor | é¢„æµ‹å™ªå£° |

### SimpleUNet æµ‹è¯•æ¨¡å‹

ç”¨äºå¿«é€Ÿæµ‹è¯•çš„ç®€åŒ–ç‰ˆæœ¬ï¼ˆæ¥è‡ª `idea.md`ï¼‰ï¼š

```python
class SimpleUNet(nn.Module):
    """
    ç®€åŒ–çš„ U-Net æ¨¡å‹ï¼Œç”¨äºæµ‹è¯•æ‰©æ•£ç®—æ³•ã€‚

    æ³¨æ„ï¼šæ­¤æ¨¡å‹ä»…ç”¨äºæµ‹è¯•ï¼Œä¸é€‚åˆå®é™…è®­ç»ƒã€‚
    """
    def __init__(self, in_channels: int, out_channels: int):
        super().__init__()
        self.conv = nn.Conv2d(in_channels + 1, out_channels, kernel_size=3, padding=1)

    def forward(self, x_t: torch.Tensor, t: torch.Tensor, condition: torch.Tensor) -> torch.Tensor:
        # ç®€å•çš„æ—¶é—´åµŒå…¥ï¼ˆæ‰©å±•æ ‡é‡åˆ°ç©ºé—´ç»´åº¦ï¼‰
        t_emb = t.view(t.size(0), 1, 1, 1).expand(-1, 1, x_t.size(2), x_t.size(3))

        # æ‹¼æ¥è¾“å…¥ï¼ˆå‡è®¾ condition ä¸ x_t å½¢çŠ¶å…¼å®¹ï¼‰
        input_tensor = torch.cat([x_t, t_emb, condition], dim=1)

        return self.conv(input_tensor)
```

---

## ğŸ§ª æµ‹è¯•ä¸è´¨é‡

### æµ‹è¯•ç­–ç•¥ï¼ˆè®¡åˆ’ï¼‰

`unet.py` åº”åŒ…å«ä»¥ä¸‹æµ‹è¯•ä»£ç ï¼š

```python
if __name__ == "__main__":
    import torch

    # æµ‹è¯•å‚æ•°
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    batch_size = 4
    in_channels = 1
    out_channels = 1
    height, width = 64, 64
    n_timesteps = 1000

    # å®ä¾‹åŒ–æ¨¡å‹
    model = UNet(
        in_channels=in_channels,
        out_channels=out_channels,
        base_channels=64,
        channel_multipliers=[1, 2, 4],
        num_res_blocks=2,
        attention_resolutions=[16]
    ).to(device)

    # åˆ›å»ºæµ‹è¯•æ•°æ®
    x_t = torch.randn(batch_size, in_channels, height, width).to(device)
    t = torch.randint(0, n_timesteps, (batch_size,)).to(device)
    condition = torch.randn(batch_size, in_channels, height, width).to(device)

    # æµ‹è¯•å‰å‘ä¼ æ’­
    print("æµ‹è¯• UNet å‰å‘ä¼ æ’­:")
    print(f"  è¾“å…¥ x_t å½¢çŠ¶: {x_t.shape}")
    print(f"  æ—¶é—´æ­¥ t å½¢çŠ¶: {t.shape}")
    print(f"  æ¡ä»¶ condition å½¢çŠ¶: {condition.shape}")

    with torch.no_grad():
        predicted_noise = model(x_t, t, condition)

    print(f"  è¾“å‡ºå™ªå£°å½¢çŠ¶: {predicted_noise.shape}")

    # éªŒè¯è¾“å‡ºå½¢çŠ¶
    assert predicted_noise.shape == x_t.shape, "è¾“å‡ºå½¢çŠ¶åº”ä¸è¾“å…¥ x_t ç›¸åŒ"

    # è®¡ç®—å‚æ•°é‡
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"\næ¨¡å‹ç»Ÿè®¡:")
    print(f"  æ€»å‚æ•°é‡: {total_params:,}")
    print(f"  å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")

    print("\nâœ“ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
```

### è´¨é‡æ£€æŸ¥æ¸…å•
- [ ] è¾“å‡ºå½¢çŠ¶ä¸è¾“å…¥ `x_t` å®Œå…¨ä¸€è‡´
- [ ] æ”¯æŒä¸åŒçš„è¾“å…¥åˆ†è¾¨ç‡
- [ ] æ—¶é—´åµŒå…¥æ­£ç¡®æ³¨å…¥åˆ°ç½‘ç»œä¸­
- [ ] è·³è·ƒè¿æ¥æ­£ç¡®å®ç°
- [ ] æ³¨æ„åŠ›æ¨¡å—åœ¨æŒ‡å®šåˆ†è¾¨ç‡æ­£å¸¸å·¥ä½œ
- [ ] ä»£ç ç¬¦åˆ PEP 8 å’Œ `coding_paradigm.md` è§„èŒƒ
- [ ] æ‰€æœ‰æ–¹æ³•åŒ…å«ç±»å‹æç¤ºå’Œæ–‡æ¡£å­—ç¬¦ä¸²

---

## â“ å¸¸è§é—®é¢˜ (FAQ)

### Q1: ä¸ºä»€ä¹ˆä½¿ç”¨ U-Net æ¶æ„ï¼Ÿ
**A**: U-Net çš„ä¼˜åŠ¿åŒ…æ‹¬ï¼š
1. **å¤šå°ºåº¦ç‰¹å¾**: ä¸‹é‡‡æ ·å’Œä¸Šé‡‡æ ·è·¯å¾„æ•æ‰ä¸åŒå°ºåº¦ä¿¡æ¯
2. **è·³è·ƒè¿æ¥**: ä¿ç•™ç©ºé—´ç»†èŠ‚ï¼Œé¿å…ä¿¡æ¯ä¸¢å¤±
3. **æˆç†Ÿç¨³å®š**: åœ¨å›¾åƒç”Ÿæˆä»»åŠ¡ä¸­éªŒè¯æœ‰æ•ˆ
4. **çµæ´»æ€§**: å¯è½»æ¾è°ƒæ•´æ·±åº¦å’Œå®½åº¦

### Q2: æ—¶é—´æ­¥åµŒå…¥ä¸ºä»€ä¹ˆé‡è¦ï¼Ÿ
**A**:
- æ¨¡å‹éœ€è¦çŸ¥é“å½“å‰å¤„äºæ‰©æ•£è¿‡ç¨‹çš„å“ªä¸ªé˜¶æ®µ
- ä¸åŒæ—¶é—´æ­¥çš„å™ªå£°æ°´å¹³ä¸åŒï¼Œéœ€è¦ä¸åŒçš„å»å™ªç­–ç•¥
- æ—¶é—´åµŒå…¥ä½¿æ¨¡å‹èƒ½å¤Ÿå­¦ä¹ æ—¶é—´ç›¸å…³çš„ç‰¹å¾

### Q3: ä½•æ—¶ä½¿ç”¨æ³¨æ„åŠ›æœºåˆ¶ï¼Ÿ
**A**:
- **ä½åˆ†è¾¨ç‡ç‰¹å¾**: é€šå¸¸åœ¨ 16Ã—16 æˆ– 8Ã—8 åˆ†è¾¨ç‡
- **è®¡ç®—æˆæœ¬**: æ³¨æ„åŠ›å¤æ‚åº¦ä¸º O(nÂ²)ï¼Œä¸é€‚ç”¨äºé«˜åˆ†è¾¨ç‡
- **æƒè¡¡**: åœ¨æ€§èƒ½å’Œè®¡ç®—æˆæœ¬ä¹‹é—´å¹³è¡¡

### Q4: `condition` å‚æ•°å¦‚ä½•ä½¿ç”¨ï¼Ÿ
**A**:
- **ç±»åˆ«æ¡ä»¶**: é€šè¿‡åµŒå…¥å±‚è½¬æ¢ä¸ºç‰¹å¾å›¾
- **æ–‡æœ¬æ¡ä»¶**: ä½¿ç”¨ CLIP æˆ– T5 ç¼–ç å™¨æå–ç‰¹å¾
- **å›¾åƒæ¡ä»¶**: ç›´æ¥æ‹¼æ¥æˆ–é€šè¿‡äº¤å‰æ³¨æ„åŠ›èåˆ
- **æ— æ¡ä»¶**: ä¼ å…¥é›¶å¼ é‡æˆ–ä¸ä½¿ç”¨

### Q5: SimpleUNet å’Œå®Œæ•´ UNet çš„åŒºåˆ«ï¼Ÿ
**A**:
| ç‰¹æ€§ | SimpleUNet | å®Œæ•´ UNet |
|------|-----------|-----------|
| ç”¨é€” | æµ‹è¯•æ‰©æ•£ç®—æ³• | å®é™…è®­ç»ƒå’Œç”Ÿæˆ |
| å¤æ‚åº¦ | å•å±‚å·ç§¯ | å¤šå±‚ä¸‹é‡‡æ ·+ä¸Šé‡‡æ · |
| æ—¶é—´åµŒå…¥ | ç®€å•æ‰©å±• | æ­£å¼¦ä½ç½®ç¼–ç  + MLP |
| æ³¨æ„åŠ› | æ—  | å¤šå¤´è‡ªæ³¨æ„åŠ› |
| æ€§èƒ½ | å¾ˆå·® | é«˜è´¨é‡ç”Ÿæˆ |

---

## ğŸ“ ç›¸å…³æ–‡ä»¶åˆ—è¡¨

### è®¡åˆ’ä¸­çš„å®ç°æ–‡ä»¶
- `D:\Tutorials\tutorials_for_claude_code\diffusion_model_implementations\models\__init__.py` - æ¨¡å—åˆå§‹åŒ–
- `D:\Tutorials\tutorials_for_claude_code\diffusion_model_implementations\models\unet.py` - U-Net å®Œæ•´å®ç°

### ç›¸å…³æ–‡æ¡£
- `D:\Tutorials\tutorials_for_claude_code\diffusion_model_implementations\idea.md` - U-Net è§„æ ¼è¯´æ˜ï¼ˆç¬¬ 3.C èŠ‚ï¼‰
- `D:\Tutorials\tutorials_for_claude_code\diffusion_model_implementations\coding_paradigm.md` - ç¼–ç¨‹è§„èŒƒ

---

## ğŸ”— å‚è€ƒèµ„æº

### U-Net åŸå§‹è®ºæ–‡
- Ronneberger et al., "U-Net: Convolutional Networks for Biomedical Image Segmentation", MICCAI 2015

### æ‰©æ•£æ¨¡å‹ä¸­çš„ U-Net å˜ä½“
- [DDPM] Ho et al. - åŸºç¡€ U-Net + æ—¶é—´åµŒå…¥ + æ³¨æ„åŠ›
- [Improved DDPM] Nichol & Dhariwal - æ”¹è¿›çš„æ¶æ„å’Œè¶…å‚æ•°
- [Guided Diffusion] Dhariwal & Nichol - æ›´æ·±çš„ç½‘ç»œå’Œè‡ªé€‚åº”å½’ä¸€åŒ–

### å®ç°å‚è€ƒ
- PyTorch U-Net: https://github.com/milesial/Pytorch-UNet
- OpenAI Guided Diffusion: https://github.com/openai/guided-diffusion
- Hugging Face Diffusers: https://github.com/huggingface/diffusers

---

**ä¸‹ä¸€æ­¥è¡ŒåŠ¨**: å®ç°å®Œæ•´çš„ UNet ç±»ï¼ŒåŒ…æ‹¬æ—¶é—´åµŒå…¥ã€æ®‹å·®å—ã€æ³¨æ„åŠ›æ¨¡å—å’Œè·³è·ƒè¿æ¥ã€‚
